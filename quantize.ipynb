{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnxruntime import quantization\n",
    "import dataset\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "from mirrornet import MirrorNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = MirrorNet()\n",
    "torch_input = torch.randn(1, 1, 32, 32)\n",
    "onnx_program = torch.onnx.dynamo_export(torch_model, torch_input)\n",
    "onnx_program.save(\"my_image_classifier.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32_path = '/home/ayush/fyp/model_mirrornet.onnx'\n",
    "model_prep_path = 'model_prep.onnx'\n",
    "\n",
    "quantization.shape_inference.quant_pre_process(model_fp32_path, model_prep_path, skip_symbolic_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# def tar_transform(f1):\n",
    "#     to_pil = transforms.ToPILImage()\n",
    "#     h, w = 384,384\n",
    "#     return np.array(transforms.Resize((h, w))(to_pil(f1)))\n",
    "\n",
    "def make_dataset(root):\n",
    "    img_list = [os.path.splitext(f)[0] for f in os.listdir(os.path.join(root, 'image')) if f.endswith('.jpg')]\n",
    "    return [\n",
    "        (os.path.join(root, 'image', img_name + '.jpg'), os.path.join(root, 'mask', img_name + '.png'))\n",
    "        for img_name in img_list]\n",
    "\n",
    "\n",
    "class ImageFolder(data.Dataset):\n",
    "    def __init__(self, root, joint_transform=None, img_transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.imgs = make_dataset(root)\n",
    "        self.joint_transform = joint_transform\n",
    "        self.img_transform = img_transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, gt_path = self.imgs[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        target = Image.open(gt_path)\n",
    "        if self.joint_transform is not None:\n",
    "            img, target = self.joint_transform(img, target)\n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageFolder(\"/home/ayush/fyp/ICCV2019_MirrorNet/MSD/test/\", img_transform = img_transform, target_transform = img_transform)\n",
    "calib_ds = torch.utils.data.Subset(ds, list(range(500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/.local/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:54: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mirrornet import MirrorNet\n",
    "import onnxruntime as ort\n",
    "\n",
    "device_ids = [0]\n",
    "torch.cuda.set_device(device_ids[0])\n",
    "net = MirrorNet().cuda(device_ids[0])\n",
    "net.eval()\n",
    "\n",
    "ort_provider = ['CPUExecutionProvider']\n",
    "if torch.cuda.is_available():\n",
    "    net.to('cuda')\n",
    "    ort_provider = ['CUDAExecutionProvider']\n",
    "\n",
    "ort_sess = ort.InferenceSession(model_fp32_path, providers=ort_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuntizationDataReader(quantization.CalibrationDataReader):\n",
    "    def __init__(self, torch_ds, batch_size, input_name):\n",
    "\n",
    "        self.torch_dl = torch.utils.data.DataLoader(torch_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        self.input_name = input_name\n",
    "        self.datasize = len(self.torch_dl)\n",
    "\n",
    "        self.enum_data = iter(self.torch_dl)\n",
    "\n",
    "    def to_numpy(self, pt_tensor):\n",
    "        return pt_tensor.detach().cpu().numpy() if pt_tensor.requires_grad else pt_tensor.cpu().numpy()\n",
    "\n",
    "    def get_next(self):\n",
    "        batch = next(self.enum_data, None)\n",
    "        if batch is not None:\n",
    "          return {self.input_name: self.to_numpy(batch[0])}\n",
    "        else:\n",
    "          return None\n",
    "\n",
    "    def rewind(self):\n",
    "        self.enum_data = iter(self.torch_dl)\n",
    "\n",
    "qdr = QuntizationDataReader(calib_ds, batch_size=1, input_name=ort_sess.get_inputs()[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q_static_opts = {\"ActivationSymmetric\":False,\n",
    "                 \"WeightSymmetric\":True}\n",
    "if torch.cuda.is_available():\n",
    "    q_static_opts = {\"ActivationSymmetric\":True,\n",
    "                  \"WeightSymmetric\":True}\n",
    "\n",
    "model_int8_path = 'model_quant.onnx'\n",
    "quantized_model = quantization.quantize_static(model_input=model_prep_path,\n",
    "                                               model_output=model_int8_path,\n",
    "                                               calibration_data_reader=qdr,\n",
    "                                               extra_options=q_static_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
